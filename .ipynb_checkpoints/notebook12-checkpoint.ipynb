{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bba665",
   "metadata": {},
   "source": [
    "<img src=\"https://www.sturgischarterschool.com/wp-content/uploads/2019/06/sturgisheader_logo.png\" alt=\"sturgis\" width=\"250\" align=\"right\"/>\n",
    "\n",
    "## Computer Science 'Beautiful Soup' notebook 12\n",
    "### Sturgis Charter Public School \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681696fb",
   "metadata": {},
   "source": [
    "Student: [your name here]\n",
    "\n",
    "Collaborators: [N/A]\n",
    "\n",
    "Notes to the teacher: [N/A]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf0839",
   "metadata": {},
   "source": [
    "![soup](soup.jpeg)\n",
    "\n",
    "### Learning Objectives for notebook \n",
    "* Set up a local server using Python\n",
    "* How to scrape a website\n",
    "\n",
    "#### Narrative\n",
    "\n",
    "Setting up a local server using Python is incredibly easy. When you are in your file finder and looking at the folder that you are interested in, and then open up a command prompt and type in the following `python3 -m http.server` If you are interested in reading up a little bit on this you can look at the [results](https://developer.mozilla.org/en-US/docs/Learn/Common_questions/set_up_a_local_testing_server) of a quick Google search. \n",
    "\n",
    "When learning a new tool, it is very helpful to get the [documentation.](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#)\n",
    "\n",
    "Now here is a [quick video](https://www.youtube.com/watch?v=gRLHr664tXA&ab_channel=TechWithTim) that includes some of the key functionality of beautiful soup. I used it as a reference when creating some of the example code below. Additionally this [website](https://pytutorial.com/beautifulsoup-find-by-text/) is helpful for how to use regular expressions in combination with beautiful soup. \n",
    "\n",
    "**note** It's possible that you don't have the urllib package. If you don't (which you would know if the following box throws an error, you can either try requests, or even better go to your command terminal and install it using pip: `pip install urllib` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3eb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "# import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad930281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open it with beautiful soup\n",
    "with open('pooh.html') as f:\n",
    "    example = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "#print(example)    \n",
    "print(example.prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50755ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5482fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example.title.string = \"My new title\"\n",
    "print(example.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f33736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example.div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3742200",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4607d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example.body.div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699cce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "allp = example.find_all(\"p\")\n",
    "print(type(allp))\n",
    "print(allp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949dc675",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltext = example.get_text()\n",
    "print(alltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.findall('Pooh [a-z]+', alltext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = example.find_all(\"p\", string=re.compile(r'donkey'))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd544b1f",
   "metadata": {},
   "source": [
    "### Question 1: Scraping a website\n",
    "For the purposes of this assigment we are not going to directly scrape a website. This is because it can be quite rude to repeatedly scrape a website--you might accidentally inconvenience them on the other end. Instead what we are going to do is copy the html of a website, and bring it into our local system. To complete question 1 you must do the following:\n",
    "\n",
    "* Copy the html of a page to your local system\n",
    "* set up a server using `python3 -m http.server`\n",
    "* load that html document into this notebook using Beautiful Soup\n",
    "\n",
    "When you find a webpage that you like, simply right click on the page, and select the save as option. It should want to save it as html. Be sure to save it into this folder, so that it is easy to access. \n",
    "\n",
    "In your command terminal when in this folder, type in `python3 -m http.server`. It will run a bit of text that looks kind of like a flask server and kind of like a jupyter notebook. You are locally hosting at port 8000. Strictly speaking this isn't necessary for you to access your html, but it's good practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Write a short script that will read in your html document using beautiful soup. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8833f6",
   "metadata": {},
   "source": [
    "### Question 2: A few simple operations\n",
    "\n",
    "Now that you have a scrape of a website, find the following things. \n",
    "\n",
    "* A list of all the `<p>` tags and their contents\n",
    "* All the words that come after the word 'the' (it's possible that it's an empty list, but unlikely.\n",
    "* The first link `<a href...>` tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a script that will get the <p> tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24674c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a script that will get all the words that follow 'the'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ceffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a script that will find all the <a href...> tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617e4d31",
   "metadata": {},
   "source": [
    "### Question 3: Building a scraper function--HL ONLY\n",
    "\n",
    "Here we're going to build a function that scrapes for specific content. It should take a url--here we're just going to use our localhost, and it should be able to find to return all sentences that have the word 'balloon' in *Winnie-the-Pooh*. \n",
    "\n",
    "**IF YOU ARE STUCK**, then I highly recommend that you reference the [documentation!](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#)\n",
    "\n",
    "*Note*: Let's get rid of the punctuation alltogether. Use a regular expression or a string replacement method to get rid of everything that is not 'a-z', 'A-Z', or ' '. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7401139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url):\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79919fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://localhost:8000/pooh.html'\n",
    "texts = scrape(url)\n",
    "print(texts[0])\n",
    "print(texts[5])\n",
    "print(texts[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0c122",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert texts[0] == 'I wonder if youve got such a thing as a balloon about you'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a660fa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "check = 'Well it just happened that you had been to a party the day'\\\n",
    "' before atthe house of your friend Piglet and you had balloons at the party Youhad had'\\\n",
    "' a big green balloon and one of Rabbits relations had had a bigblue one and had left it'\\\n",
    "' behind being really too young to go to aparty at all and so you had brought the green one '\n",
    "\n",
    "for i, j in zip(texts[5], check):\n",
    "    assert i == j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68305d69",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert texts[10] == 'You look like a Bear holding on to a balloon you said'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7eaad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
